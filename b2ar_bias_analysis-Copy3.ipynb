{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this iPython notebook, we will featurize MOR ligand binding simulation by pairwise distances between the ligand and different receptor residues. We will then perform tICA and prospectively build an MSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from PDB_Order_Fixer import PDB_Order_Fixer\n",
    "import mdtraj as md\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import copy\n",
    "from functools import partial \n",
    "import operator\n",
    "import time\n",
    "\n",
    "import random \n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "import sys\n",
    "from io_functions import *\n",
    "from custom_clusterer import *\n",
    "from custom_tica import *\n",
    "from custom_featurizer import *\n",
    "from pdb_editing import *\n",
    "from analysis import *\n",
    "from io_functions import *\n",
    "#from topology_fixing import *\n",
    "from subsampling import *\n",
    "from conversions import *\n",
    "from custom_msm import *\n",
    "from grids import *\n",
    "from docking_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are operating on biox3\n"
     ]
    }
   ],
   "source": [
    "from detect_intermediates import *\n",
    "from interpret_tICs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from b2ar_feature_types import *\n",
    "from get_variable_names import *\n",
    "from b2ar_tica_config import *\n",
    "from residue import Residue, Atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#set_palette('Set1', n_colors=15, desat=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_feature_name = copy.deepcopy(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schemes = ['closest-heavy']\n",
    "#schemes = [\"closest-heavy\", \"CA\"]\n",
    "#feature_name = \"%s-CA\" %ori_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rho = 0.01\n",
    "n_components=10\n",
    "rho_string = \"_rho0pt01\"\n",
    "n_clusters = 100\n",
    "n_samples = 5\n",
    "lag_time=5\n",
    "precision = \"SP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enf/b2ar_analysis/featuresall_residues_2rh1_3sn6_under_cutoff6A\n",
      "/home/enf/b2ar_analysis/featuresall_residues_2rh1_3sn6_under_cutoff6A\n"
     ]
    }
   ],
   "source": [
    "(active_ref_dir, inactive_ref_dir, simulation_ref_dir, scripts_dir,\n",
    "          ligand_dir, agonist_dir, inverse_agonist_dir, biased_agonist_dir, ref_receptors_dir, whole_trajectory_pnas,\n",
    "          sasa_file) = get_base_files(base)\n",
    "\n",
    "tica_dir = get_tica_dir(base, is_sparse, lag_time, n_components, feature_name, \n",
    "                                 wolf_string, shrinkage_string, rho_string)\n",
    "ori_tica_dir = copy.deepcopy(tica_dir)\n",
    "features_dir = get_features_dir(base, feature_name)\n",
    "\n",
    "landmarks_dir = get_landmarks_dir(tica_dir)\n",
    "analysis_dir = get_analysis_dir(tica_dir, n_clusters, sampling_method)\n",
    "gmm_dir = get_gmm_dir(tica_dir)\n",
    "rf_dirdir = get_rf_dir(tica_dir)\n",
    "\n",
    "\n",
    "ref_tica_dir, ref_tica_coords = get_ref_tica_dirs(tica_dir)\n",
    "\n",
    "graph_file = get_graph_file(tica_dir, msm_lag_time, n_clusters)\n",
    "\n",
    "pnas_titles =  [\"tm6_tm3_dist\", \"rmsd_npxxy_inactive\", \"rmsd_npxxy_active\", \"rmsd_connector_inactive\", \"rmsd_connector_active\"]\n",
    "pnas_features_dir = analysis_dir\n",
    "\n",
    "\n",
    "(clusterer_dir, msm_model_dir, macrostate_dir, features_known, model_dir, projected_features_dir,\n",
    "         projection_operator_dir, ktica_fit_model_filename, ktica_projected_data_filename, nystroem_data_filename,\n",
    "         mutual_information_csv, pearson_csv) = get_tica_files(base, tica_dir, n_clusters, msm_lag_time, n_macrostates)\n",
    "\n",
    "(standardized_features_dir, feature_residues_csv, feature_residues_pkl,\n",
    "          contact_csv, ref_features_dir) = get_feature_files(features_dir)\n",
    "\n",
    "(kmeans_csv, tica_coords_csv, features_csv, active_rmsd_dir, inactive_rmsd_dir, active_pnas_dir, inactive_pnas_joined, active_pnas_joined,\n",
    "        clusters_map_file, ktica_clusters_map_file, analysis_file, combined_file, docking_summary, docking_joined, docking_z_scores_csv,\n",
    "        aggregate_docking, aggregate_docking_joined, docking_pnas_joined, aggregate_docking_pnas, aggregate_docking_pnas_joined, docking_multiple_ligands,\n",
    "        docking_distances_file, docking_pdf, mmgbsa_docking_distances, pnas_coords, mmgbsa_dir, mmgbsa_csv, mmgbsa_pdf, aggregate_mmgbsa,\n",
    "        aggregate_mmgbsa_joined, aggregate_mmgbsa_pnas_joined, mmgbsa_z_scores_csv, active_clusters_csv, intermediate_clusters_csv,\n",
    "        inactive_clusters_csv, pnas_clusters_averages, tica_clusters_averages, tica_classes_csv, tica_samples_csv, subgraph_save_base,\n",
    "        degree_save_base, degree_map_csv, degree_z_map_csv, aggregate_docking_pnas_degree_z_joined, tic_residue_csv, feature_coefs_csv,\n",
    "        duplicated_feature_coefs_csv) = get_analysis_files(analysis_dir, n_clusters, tica_dir, tica_dir, sampling_method, n_samples, precision,\n",
    "                                                           msm_lag_time)\n",
    "\n",
    "(inactive_pnas_distances_dir, active_pnas_distances_dir, active_pnas_all_distances_dir,\n",
    "          inactive_pnas_distances_new_csv, active_pnas_distances_new_csv, active_pnas_joined, active_pnas_means, pnas_coords_dir,\n",
    "          pnas_coords_csv, pnas_all_coords_csv, pnas_coords_hexbin_dir, pnas_coords_co_crystallized_docking_dir,\n",
    "          pnas_coords_active_colors_dir, user_defined_features_file, reaction_coordinates_trajs_file) = get_pnas_files(whole_trajectory_pnas, pnas_features_dir)\n",
    "\n",
    "features_dir = get_features_dir(base, feature_name)\n",
    "\n",
    "\n",
    "\n",
    "graph_file = get_graph_file(tica_dir, msm_lag_time, n_clusters)\n",
    "(scripts_dir, pymol_fixpdb_dir) = get_script_dir(scripts_dir)\n",
    "(save_dir, reimaged_dir, mae_dir, combined_reimaged_dir, grid_dir, docking_dir) = get_docking_dirs(tica_dir, n_clusters, n_components, n_samples, sampling_method, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/enf/b2ar_analysis/sparse-tICA_t5_n_components10all_residues_2rh1_3sn6_under_cutoff6A_regularization_wolf_autoShrinkage_rho0pt01'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tica_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(features_dir): os.makedirs(features_dir)\n",
    "import custom_featurizer\n",
    "reload(custom_featurizer)\n",
    "from custom_featurizer import *\n",
    "featurize_contacts_custom(traj_dir, features_dir = features_dir, \n",
    "                          traj_ext = traj_ext, contact_residue_pairs_file = feature_residues_pkl, \n",
    "                          structures = [active_ref_dir, inactive_ref_dir],  \n",
    "                          contact_residues =  contact_residues, residues_map = None, \n",
    "                          contact_cutoff = 0.66, parallel = False, \n",
    "                          exacycle = exacycle, load_from_file=False, schemes=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_normalizer(features_dir)\n",
    "fit_and_transform(features_directory = features_dir, model_dir = tica_dir, stride=5, lag_time = lag_time, n_components = n_components, sparse = sparse, wolf = wolf, rho = rho, shrinkage = shrinkage, parallel=True, traj_ext = traj_ext, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tica_object = verboseload(projection_operator_dir)\n",
    "print(tica_object.timescales_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic_components_dir = tica_dir\n",
    "important_contact_features = interpret_tIC_components(projection_operator_dir, tic_components_dir, feature_residues_pkl, n_tica_components=n_components, percentile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tica_coords = verboseload(projected_features_dir)\n",
    "pnas_coords = verboseload(pnas_coords_dir)\n",
    "for pnas_coord in pnas_coords: pnas_coord[:,0]*=7.14\n",
    "tica_names = [\"tIC.%d\" %i for i in range(1,n_components+1)]\n",
    "pnas_names = [\"tm6_tm3_dist\", \"rmsd_npxxy_inactive\", \"rmsd_npxxy_active\", \"rmsd_connector_inactive\", \"rmsd_connector_active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_minikmeans(tica_dir, projected_features_dir, traj_dir, n_clusters=n_clusters, clusterer_dir=clusterer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docking_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import custom_clusterer\n",
    "reload(custom_clusterer)\n",
    "from custom_clusterer import *\n",
    "\n",
    "samples_indices_file = \"%s/samples_indices.h5\" %analysis_dir\n",
    "samples_dir = \"%s/clusterer_%dclusters_%dsamples\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir):\n",
    "    os.makedirs(samples_dir)\n",
    "#sample_from_clusterer(clusterer_dir, projected_features_dir, get_trajectory_files(traj_dir, \".h5\"), \n",
    "#                      n_samples, samples_dir, samples_indices_file, structure=None,\n",
    "#                      residue_cutoff=10000, parallel=True,\n",
    "#                      worker_pool=None)\n",
    "clusters_map = make_clusters_map(verboseload(clusterer_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def calculate_cluster_averages_per_feature(clusterer, features):\n",
    "  n_clusters = clusterer.n_clusters \n",
    "  concatenated_clusters = np.concatenate(clusterer.labels_)\n",
    "  concatenated_features = np.concatenate(features)\n",
    "  cluster_averages = np.zeros((n_clusters, concatenated_features.shape[1]))\n",
    "  for i in range(0, n_clusters):\n",
    "    rows = np.where(concatenated_clusters == i)[0]\n",
    "    means = np.mean(concatenated_features[rows,:], axis=0)\n",
    "    cluster_averages[i,:] = means\n",
    "  return cluster_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterer = verboseload(clusterer_dir)\n",
    "cluster_averages = calculate_cluster_averages_per_feature(clusterer, pnas_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(cluster_averages[:,0], cluster_averages[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_averages = pd.DataFrame(cluster_averages, columns=pnas_names)\n",
    "active_clusters = cluster_averages.loc[(cluster_averages[\"rmsd_npxxy_active\"] < 0.5) & (cluster_averages[\"tm6_tm3_dist\"] > 12.) & (cluster_averages[\"tm6_tm3_dist\"] < 15.)]\n",
    "inactive_clusters = cluster_averages.loc[(cluster_averages[\"rmsd_npxxy_active\"] > 0.5) & (cluster_averages[\"tm6_tm3_dist\"] <10.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data_vs_data(np.concatenate(tica_coords), np.concatenate(pnas_coords), tica_names, pnas_names, analysis_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_columns(tica_dir, projected_features_dir, titles = [\"tIC%d\" %j for j in range(1,11)], tICA = True, scale = 1.0, refcoords_file = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_ligands(agonist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ligands(biased_agonist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docking_multiple_ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AsyncMapResult: chdir>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "print(len(rc.ids))\n",
    "dview = rc[:]\n",
    "dview.map(os.chdir, ['/home/enf/b2ar_analysis/conformation']*len(rc.ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_name_residues_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import b2ar_feature_types\n",
    "reload(b2ar_feature_types)\n",
    "from b2ar_feature_types import *\n",
    "\n",
    "import analysis\n",
    "reload(analysis)\n",
    "from analysis import *\n",
    "\n",
    "import custom_featurizer\n",
    "reload(custom_featurizer)\n",
    "from custom_featurizer import *\n",
    "\n",
    "user_defined_features_dir = \"%s/user_defined_features\" %traj_dir\n",
    "if not os.path.exists(user_defined_features_dir):\n",
    "    os.makedirs(user_defined_features_dir)\n",
    "\n",
    "compute_user_defined_features_wrapper(traj_dir, traj_ext, inactive_dir, active_dir, None,\n",
    "                                        feature_name_residues_dict, user_defined_features_file, user_defined_features_dir, worker_pool=None, \n",
    "                                      parallel=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ligands_dir = \"/home/enf/b2ar_analysis/all_ligands\"\n",
    "get_ligands(all_ligands_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grids\n",
    "reload(grids)\n",
    "from grids import *\n",
    "\n",
    "grid_center = \"64.4, 16.9, 11.99\"\n",
    "\n",
    "\n",
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "print(\"biased_ligands\")\n",
    "print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "#remove_ter(reimaged_dir)\n",
    "#reorder(reimaged_dir)\n",
    "\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "\n",
    "mehrdad_dir = \"%s/mehrdad_ligands\" %agonist_dir\n",
    "all_ligands_dir = \"/home/enf/b2ar_analysis/all_ligands\"\n",
    "\n",
    "#chosen_ligands = [\"3p0g_lig\", 'Ici118551', \"r_isopreterenol\", \"r_epinephrine\", \"s-carazolol\"]\n",
    "#agonist_ligands = [a for a in agonist_ligands if \"TA\" not in a]\n",
    "\n",
    "#pprep(mae_dir, ref = active_ref_dir, chosen_receptors = chosen_receptors, worker_pool=None, parallel=True)\n",
    "#generate_grids(mae_dir, grid_center, grid_dir, remove_lig = \"BIA\", chosen_receptors = chosen_receptors, worker_pool=None, outer_box=25.)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, all_ligands_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = False, chosen_receptors = False, parallel = False, grid_ext = \".zip\", worker_pool=dview)\n",
    "\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir,  biased_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = biased_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = md.load(\"/home/enf/b2ar_analysis/subsampled_reimaged_amber/C-02.h5\")\n",
    "top = t.topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(c.id, c.n_residues) for c in t.topology.chains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import analysis\n",
    "reload(analysis)\n",
    "from analysis import *\n",
    "\n",
    "docking_results = analyze_docking_results_multiple(docking_dir, precision = \"XP\", ligands = chosen_ligands, summary = docking_multiple_ligands, redo = True)\n",
    "c = compute_cluster_averages(None, csv_filename=docking_multiple_ligands, save_csv=aggregate_docking)\n",
    "\n",
    "#compute_aggregate_scores(docking_multiple_ligands, inverse_agonists = inverse_ligands, summary = aggregate_docking, z_scores_csv = docking_z_scores_csv)\n",
    "#aggregate_docking_joined_map = convert_csv_to_joined_map(aggregate_docking, aggregate_docking_joined)[0]\n",
    "#aggregate_docking_means = calc_mean(aggregate_docking_joined_map)\n",
    "#write_map_to_csv(aggregate_docking_joined, aggregate_docking_means, [\"cluster\", \"mean_aggregate_docking_z_score\"])\n",
    "#r['do.analysis'](tica_dir, analysis_dir, pnas_coords_csv, tica_coords_csv, features_dir, docking_multiple_ligands)\n",
    "#tics_vs_docking_file = \"%s/tICA_vs_docking.pdf\" % analysis_dir\n",
    "#plot_tICs_vs_docking(docking_multiple_ligands, tica_coords_csv, tics_vs_docking_file, chosen_ligand=\"s-carvedilol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lag_time = 25\n",
    "msm_model_dir = \"%s/msm_lag_time%d.h5\" % (tica_dir, lag_time)\n",
    "build_msm(clusterer_dir, lag_time=lag_time, msm_model_dir=msm_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_clusters = 100\n",
    "n_samples=5\n",
    "\n",
    "clusterer_tICs_1_2_3_filename = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "clusterer_tICs_1_2_3_map_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_map.json\" %(tica_dir, n_clusters, n_samples)\n",
    "tics_to_cluster = [0, 1, 2]\n",
    "\n",
    "projected_features_tICs_1_2_3_filename = \"%s/projected_features_tICs_1_2_3.h5\" %tica_dir\n",
    "projected_features = verboseload(projected_features_dir)\n",
    "projected_features = [f[:, [0, 1, 2]] for f in projected_features]\n",
    "verbosedump(projected_features, projected_features_tICs_1_2_3_filename)\n",
    "\n",
    "cluster_minikmeans(tica_dir, projected_features_dir, traj_dir, n_clusters=n_clusters, clusterer_dir=clusterer_tICs_1_2_3_filename, tICs=tics_to_cluster)\n",
    "clusterer_tICs_1_2_3 = verboseload(clusterer_tICs_1_2_3_filename)\n",
    "clusterer_tICs_1_2_3_map = make_clusters_map(clusterer_tICs_1_2_3)\n",
    "samples_dir = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_dir = \"/home/enf/b2ar_analysis/reference_receptors\"\n",
    "grid_dir = \"/home/enf/b2ar_analysis/reference_grids\"\n",
    "docking_dir = \"/home/enf/b2ar_analysis/reference_docking/docking_SP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grids\n",
    "reload(grids)\n",
    "from grids import *\n",
    "\n",
    "grid_center = \"64.4, 16.9, 11.99\"\n",
    "\n",
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "#print(chosen_receptors)\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "#print(\"biased_ligands\")\n",
    "#print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "#remove_ter(reimaged_dir)\n",
    "#reorder(reimaged_dir)\n",
    "\n",
    "mehrdad_dir = \"%s/mehrdad_ligands\" %agonist_dir\n",
    "\n",
    "hts_dir = \"/home/enf/htbc/sdfs\"\n",
    "\n",
    "\n",
    "#grid_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_grids\" %(tica_dir, n_clusters, n_samples)\n",
    "#docking_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_docking\" %(tica_dir, n_clusters, n_samples)\n",
    "\n",
    "#prepare_ligands(inverse_agonist_dir, [\".sdf\"])\n",
    "#prepare_ligands(hts_dir, [\".sdf\"], worker_pool=None, parallel=True)\n",
    "\n",
    "#agonist_ligands = get_ligands(agonist_dir)\n",
    "#inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "\n",
    "\n",
    "#print(mehrdad_dir)\n",
    "#mehrdad_ligands = get_ligands(mehrdad_dir)\n",
    "#print(\"Mehrdad ligands:\")\n",
    "#print(mehrdad_ligands)\n",
    "\n",
    "#pprep(mae_dir, ref = active_ref_dir, chosen_receptors = chosen_receptors, worker_pool=None, parallel=True)\n",
    "#generate_grids(mae_dir, grid_center, grid_dir, remove_lig = \"BIA\", chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "#unzip_receptors(grid_dir, chosen_receptors, worker_pool=dview)\n",
    "\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, hts_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = False, chosen_receptors = False, parallel = False, grid_ext = \".zip\", worker_pool=dview)\n",
    "\n",
    "\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = False, parallel = \"ligand\", grid_ext = \".zip\", worker_pool=None)\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, biased_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = biased_ligands, chosen_receptors = False, parallel = \"ligand\", grid_ext = \".zip\", worker_pool=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#agonist_ligands = [a for a in get_ligands(agonist_dir) if \"ta\" not in a and \"TA\" not in a]\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = False, parallel = \"ligand\", grid_ext = \".zip\", worker_pool=None)\n",
    "\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, inverse_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = inverse_ligands, chosen_receptors = False, parallel = \"ligand\", grid_ext = \".zip\", worker_pool=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    import custom_clusterer\n",
    "reload(custom_clusterer)\n",
    "from custom_clusterer import *\n",
    "\n",
    "import custom_msm\n",
    "reload(custom_msm)\n",
    "from custom_msm import *\n",
    "\n",
    "samples_dir = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree\" %(tica_dir, n_clusters, n_samples)\n",
    "samples_indices_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_indices.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n",
    "\n",
    "#sample_from_clusterer(clusterer_tICs_1_2_3_filename, projected_features_tICs_1_2_3_filename, get_trajectory_files(traj_dir, traj_ext), \n",
    "#                      n_samples, samples_dir, samples_indices_file,\n",
    "#                      worker_pool=None, parallel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterer_tICs_1_2_3_samples = {}\n",
    "with open(clusters_map_file) as f:\n",
    "    clusterer_samples = json.load(f)\n",
    "    clusterer_samples = {int(k):[tuple(vi[0:2]) for vi in v] for k,v in list(clusterer_samples.items())}\n",
    "#print(clusterer_samples)\n",
    "original_samples = set()\n",
    "for key, sample_list in clusterer_samples.iteritems():\n",
    "    for sample in sample_list:\n",
    "        original_samples.add(sample)\n",
    "#print(original_samples)\n",
    "for cluster_id, sample_list in clusterer_tICs_1_2_3_map.iteritems():\n",
    "    if cluster_id not in clusterer_tICs_1_2_3_samples.keys():\n",
    "        clusterer_tICs_1_2_3_samples[cluster_id] = []\n",
    "    for sample in sample_list:\n",
    "        if sample in original_samples:\n",
    "            clusterer_tICs_1_2_3_samples[cluster_id].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_center = \"64.4, 16.9, 11.99\"\n",
    "\n",
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "#print(chosen_receptors)\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "#print(\"biased_ligands\")\n",
    "#print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "#remove_ter(reimaged_dir)\n",
    "#reorder(reimaged_dir)\n",
    "\n",
    "mehrdad_dir = \"%s/mehrdad_ligands\" %agonist_dir\n",
    "\n",
    "\n",
    "grid_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_grids\" %(tica_dir, n_clusters, n_samples)\n",
    "docking_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_docking\" %(tica_dir, n_clusters, n_samples)\n",
    "\n",
    "#prepare_ligands(inverse_agonist_dir, [\".sdf\"])\n",
    "#prepare_ligands(agonist_dir, [\".sdf\"])\n",
    "\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "\n",
    "\n",
    "#print(mehrdad_dir)\n",
    "mehrdad_ligands = get_ligands(mehrdad_dir)\n",
    "#print(\"Mehrdad ligands:\")\n",
    "#print(mehrdad_ligands)\n",
    "\n",
    "#pprep(mae_dir, ref = active_ref_dir, chosen_receptors = chosen_receptors, worker_pool=None, parallel=True)\n",
    "#generate_grids(mae_dir, grid_center, grid_dir, remove_lig = \"BIA\", chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "#unzip_receptors(grid_dir, chosen_receptors, worker_pool=dview)\n",
    "\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir,  biased_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = biased_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "\n",
    "\n",
    "#agonist_ligands = [a for a in get_ligands(agonist_dir) if \"ta\" not in a and \"TA\" not in a]\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, mehrdad_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = False, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, inverse_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = inverse_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docking_multiple_ligands = \"%s/all_docking_scores.csv\" % docking_dir\n",
    "aggregate_docking = \"%s/aggregate_docking.csv\" % docking_dir\n",
    "\n",
    "analyze_docking_results_multiple(docking_dir, precision = \"SP\", ligands = biased_ligands + agonist_ligands, summary = docking_multiple_ligands, redo = True)\n",
    "compute_cluster_averages(None, csv_filename=docking_multiple_ligands, save_csv=aggregate_docking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg = pd.read_csv(aggregate_docking)\n",
    "aggs = df_agg.sort([' nebivolol'], ascending=[0])\n",
    "aggs.iloc[0:10]\n",
    "ranked = aggs.rank(axis=0, method='average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranked.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dock_ligands_and_receptors(grid_dir, docking_dir, inverse_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = inverse_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_clusters = 500\n",
    "n_samples=10\n",
    "\n",
    "clusterer_tICs_1_2_3_4_filename = \"%s/clusterer_tICs_1_2_3_4_%dclusters_%dsamples.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "clusterer_tICs_1_2_3_4_map_file = \"%s/clusterer_tICs_1_2_3_4_%dclusters_%dsamples_map.json\" %(tica_dir, n_clusters, n_samples)\n",
    "tics_to_cluster = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "cluster_minikmeans(tica_dir, projected_features_dir, traj_dir, n_clusters=n_clusters, clusterer_dir=clusterer_tICs_1_2_3_4_filename, tICs=tics_to_cluster)\n",
    "clusterer_tICs_1_2_3_4 = verboseload(clusterer_tICs_1_2_3_4_filename)\n",
    "clusterer_tICs_1_2_3_4_map = make_clusters_map(clusterer_tICs_1_2_3_4)\n",
    "samples_dir = \"%s/clusterer_tICs_1_2_3_4_%dclusters_%dsamples_samples\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n",
    "#sample_clusters(clusterer_tICs_1_2_3_4_filename, projected_features_dir, traj_dir, traj_ext, save_dir=samples_dir, n_samples=n_samples, method = sampling_method, clusters_map_file = clusterer_tICs_1_2_3_4_map_file, tICs=[0, 1, 2, 3], worker_pool=dview)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_center = \"64.4, 16.9, 11.99\"\n",
    "\n",
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "print(\"biased_ligands\")\n",
    "print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "#remove_ter(reimaged_dir)\n",
    "#reorder(reimaged_dir)\n",
    "\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "mehrdad_dir = \"%s/mehrdad_ligands\" %agonist_dir\n",
    "\n",
    "agonist_ligands = [a for a in agonist_ligands]\n",
    "\n",
    "grid_dir =  \"%s/clusterer_tICs_1_2_3_4_%dclusters_%dsamples_grids\" %(tica_dir, n_clusters, n_samples)\n",
    "docking_dir =  \"%s/clusterer_tICs_1_2_3_4_%dclusters_%dsamples_docking\" %(tica_dir, n_clusters, n_samples)\n",
    "\n",
    "#prepare_ligands(mehrdad_dir, [\".mol\"])\n",
    "#prepare_ligands(agonist_dir, [\".sdf\"])\n",
    "print(mehrdad_dir)\n",
    "mehrdad_ligands = get_ligands(mehrdad_dir)\n",
    "print(\"Mehrdad ligands:\")\n",
    "print(mehrdad_ligands)\n",
    "\n",
    "#pprep(mae_dir, ref = active_ref_dir, chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "#generate_grids(mae_dir, grid_center, grid_dir, remove_lig = \"BIA\", chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "#unzip_receptors(grid_dir, chosen_receptors, worker_pool=dview)\n",
    "\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir,  biased_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = biased_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "agonist_ligands = [a for a in get_ligands(agonist_dir) if \"ta\" not in a and \"TA\" not in a]\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "#inverse_ligands = [lig for lig in inverse_ligands if \"carazolol\" in lig]\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir,  inverse_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = inverse_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, mehrdad_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = False, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### n_clusters = 25\n",
    "n_samples=100\n",
    "\"\"\"\n",
    "clusterer_tICs_1_2_filename = \"%s/clusterer_tICs_1_2_%dclusters_%dsamples.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "clusterer_tICs_1_2_map_file = \"%s/clusterer_tICs_1_2_%dclusters_%dsamples_map.json\" %(tica_dir, n_clusters, n_samples)\n",
    "tics_to_cluster = [0, 1]\n",
    "\n",
    "\n",
    "cluster_minikmeans(tica_dir, projected_features_dir, traj_dir, n_clusters=n_clusters, clusterer_dir=clusterer_tICs_1_2_filename, tICs=tics_to_cluster)\n",
    "clusterer_tICs_1_2 = verboseload(clusterer_tICs_1_2_filename)\n",
    "clusterer_tICs_1_2_map = make_clusters_map(clusterer_tICs_1_2)\n",
    "samples_dir = \"%s/clusterer_tICs_1_2_%dclusters_%dsamples_samples\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n",
    "\"\"\"\n",
    "import custom_clusterer\n",
    "reload(custom_clusterer)\n",
    "from custom_clusterer import *\n",
    "sample_clusters(clusterer_tICs_1_2_filename, projected_features_dir, traj_dir, traj_ext, save_dir=samples_dir, n_samples=n_samples, method = sampling_method, clusters_map_file = clusterer_tICs_1_2_map_file, tICs=[0, 1], worker_pool=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rc.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "print(\"biased_ligands\")\n",
    "print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "remove_ter(reimaged_dir)\n",
    "reorder(reimaged_dir)\n",
    "\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "\n",
    "agonist_ligands = [a for a in agonist_ligands if \"TA\" not in a and \"ta\" not in a]\n",
    "print(agonist_ligands)\n",
    "\n",
    "grid_dir =  \"%s/clusterer_tICs_1_2_%dclusters_%dsamples_grids\" %(tica_dir, n_clusters, n_samples)\n",
    "docking_dir =  \"%s/clusterer_tICs_1_2_%dclusters_%dsamples_docking\" %(tica_dir, n_clusters, n_samples)\n",
    "\n",
    "pprep(mae_dir, ref = active_ref_dir, chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "generate_grids(mae_dir, grid_center, grid_dir, remove_lig = \"BIA\", chosen_receptors = chosen_receptors, worker_pool=dview)\n",
    "unzip_receptors(grid_dir, chosen_receptors, worker_pool=dview)\n",
    "\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir,  biased_agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = biased_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n",
    "#dock_ligands_and_receptors(grid_dir, docking_dir, agonist_dir, precision = precision, ext = \"-out.maegz\", chosen_ligands = agonist_ligands, chosen_receptors = chosen_receptors, parallel = None, grid_ext = \".grd\", worker_pool=dview)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_file = \"%s/msm_lag_time%d_graph.graphml\" % (tica_dir, lag_time)\n",
    "construct_graph(msm_model_dir, clusterer_dir, n_clusters, 5, 5, graph_file, inactive = None, active = None, pnas_clusters_averages = None, tica_clusters_averages = None, docking=None, macrostate = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import custom_msm\n",
    "reload(custom_msm)\n",
    "from custom_msm import *\n",
    "msm_file = msm_model_dir\n",
    "sampled_frames_file = \"%s/msm100_frames.h5\" %tica_dir\n",
    "msm_trajectory_filename = \"%s/msm100_1000frames\" %tica_dir\n",
    "make_msm_trajectory(msm_file, projected_features_dir, traj_dir, sampled_frames_file, clusterer_dir, msm_trajectory_filename, \n",
    "                    n_clusters, start_cluster=22, n_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytraj = md.load(\"/home/amir/Post_Process/GPCR/MOR/LIG_path/BU_path/h5_trajectories/rep_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(mytraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del mytraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = crystal_structure.atom_slice(range(0,400))\n",
    "subset.xyz\n",
    "print(subset.xyz)\n",
    "distances = md.compute_contacts(subset)\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances0 = distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances0 = np.nan_to_num(distances0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(distances0 > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msmbuilder.lumping.pcca_plus import PCCAPlus\n",
    "n_macrostates = 50\n",
    "lumper = PCCAPlus(n_macrostates)\n",
    "msm_obj = verboseload(msm_model_dir)\n",
    "lumper = lumper.from_msm(msm=msm_obj, n_macrostates=n_macrostates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cluster in inactive_clusters.index.values:\n",
    "    if cluster in msm_obj.mapping_.keys():\n",
    "        microstate = msm_obj.mapping_[cluster]\n",
    "        macrostate = lumper.microstate_mapping_[microstate]\n",
    "        if macrostate == 8: print(macrostate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
